<!DOCTYPE html>
<html>
    <head>
        <title>Ziyi Liu</title>
        <link rel="stylesheet" href="index.css">
        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Zenh87qX5JnK2Jl0vWa8Ck2rdkQ2Bzep5IDxbcnCeuOxjzrPF/et3URy9Bv1WTRi" crossorigin="anonymous">
    </head>
    <body>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js" integrity="sha384-oBqDVmMz9ATKxIep9tiCxS/Z9fNfEXiDAYTujMAeBAsjFuCZSmKbSSUnQlmh/jp3" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.min.js" integrity="sha384-IDwe1+LCz02ROU9k972gdyvl+AESN10+x7tBKgc9I5HFtuNz0wWnPclzo6p9vxnk" crossorigin="anonymous"></script>
        
        <!-- <div class="navbar  fixed-top">
            <div class="container-sm text-center">
            
              <div class="d-flex flex-row-reverse bd-highlight" id="navbarNav"> 
                <ul class="navbar-nav  ">
                  <
                </ul>
             
            </div>
        </div> -->
        
        <div class="navbar navbar-expand-sm bg-light" id="navbarScroll">
            <ul class="navbar-nav ms-auto mb-2 mb-lg-0">
               <li class="nav-item">
                    <a class="nav-link" aria-current="page" href="#research">Research</a>
                  </li>
                  <li class="nav-item">
                    <a class="nav-link" href="#project">Projects</a>
                  </li>
                  <li class="nav-item">
                    <a class="nav-link" href="#publication">Publications</a>
                  </li>
                  <li class="nav-item">
                    <a class="nav-link" href="CV_Ziyi_Liu.pdf" target="_blank">CV</a>
                  </li>
              
            </ul>
          </div>
          </div>
        <div class="container ">
         
            <div class="row">
                <div class="col-5 text-center">
                    <img class="img-thumbnail" src="selfie1.JPG">
                    
                    <p id="caption"> Taken in Seattle(Credit to Tiffany&#128522;)</p>
                    <a href ="https://twitter.com/liuziyi93">[Twitter]</a>
                    <a href ="https://www.linkedin.com/in/ziyi-liu-803/">[Linkedin]</a>
                    <a href = "https://github.com/liuziyi219">[Github]</a>
                    <a href = "https://scholar.google.com/citations?user=HGO-C1gAAAAJ&hl=en">[Google Scholar]</a>
                   
                    <br>
                   
                    <p id="email">Email: zliu2803[at]usc[dot]edu</p>
                </div>
               
                <div class="col-7">
                  <h1>Ziyi Liu</h1>
                  Hi thereðŸ‘‹ , I am a second-year PhD student at the University of Southern California, advised by Prof. Jieyu Zhao in the <a href="https://jyzhao.net/lab.html">LIME Lab</a>. Previously, I earned my master's degree at USC and worked as a Research Assistant in USC ISI's Ink Lab for two years under the guidance of Professor Xiang Ren. My research primarily focuses on social reasoning and trustworthy NLP, particularly evaluating LLM behavior and aligning LLM values with human values in human-LLM interaction. 
                  
                  My work is driven by two key questions: 
                  <ul>
                  <li> How can we make interactions between models and humans more seamless? </li>
                  <li> How can we ensure the faithfulness of LLMs and avoid hallucinations during interactions?</li>
                  </ul>
                  <!-- <p>Hi thereðŸ‘‹ , I am a second-year PhD student at the University of Southern California advised by Prof. Jieyu Zhao in <a href="https://jyzhao.net/lab.html">LIME Lab</a>. Previously, I obtained my master degree in USC and I was also a Research Assistant in USC ISI - Ink Lab for two years, advised by Professor Xiang Ren. My current research is focused on explainable AI and human-in-the-loop in NLP models. More specifically, we look into how machine explanation benefits models and users, and how human intervention improves model performance.  I am also very interested in grounding natural language, and took the class of it. I think this is a research field that is full of challenges but a very promising direction for NLP. </p>
                   <p>My research interests mainly include:</p>  
                   <ul>
                       <li>how machine learning can benefit human and augment human intelligence; how human-in-the-loop techniques better intervene into a model</li>
                       <li>how should we explain the model, and how can we align the model's reasoning process with human's thinking process</li>
                       <li>Social bias mitigation in language model, and how to let model have social intelligence</li>
                     <ul>-->

                  <p style="font-weight: bold;"> I am open to collaboration! If you are a master or undergraduate student in USC, please fill in this <a href="https://docs.google.com/forms/d/e/1FAIpQLSccWLXFT5mGDY5n-RG60gxO30u0gjjtsIJMvQX-axq_oIztTA/viewform">form</a> first before
                  contacting me. If you are a PhD student from another university, feel free to drop me an email! </p>

                  <p style="font-weight: bold;"> I am looking for 2025 Summer Research internship! </p>
  
                    
                </div>
                <hr>
                <div class ='row'>
                    <h1>News</h1>
                    <p id="news">Mar: I will join Microsoft this summer for internship. I will work on social intelligence and agent! </p>
                   
                    <p id="news">Sept 19th 2024: Our paper <a href="https://arxiv.org/abs/2406.12203">'InterIntent: Invesigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Environment'</a> got ACCEPTED at EMNLP 2024! See you guys in Miami &#129395; </p>
                    <p id="news">Sept 19th 2024: Our paper <a href="https://arxiv.org/abs/2311.09603">'Self-Contradictory Reasoning Evaluation and Detection'</a> got ACCEPTED as Findings in EMNLP 2024!  &#129395; </p>
              
                    
                    
                    <p id="news">May 1st 2023: Our paper 'Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-Text Rationales' got ACCEPTED at ACL 2023! &#129395; </p>
                </div>
                <hr>



                
                <div id='publication' class="row" width = "1000px">
                    <h1>Publications</h1>
                    <h3>2024</h3>
                    <p style="font-weight:bold;font-size:20px;">InterIntent: Invesigating Social Intelligence of LLMs via Intention Understanding in an Interactive Game Environment (EMNLP 2024)</p>
                    <p>Ziyi Liu*, Ahbishek Anand*, Pei Zhou, Jen-tse Huang, Jieyu Zhao (* means same contribution)</p>
                    
                    <p style="font-weight:bold;font-size:20px;">Self-Contradictory Reasoning Evaluation and Detection (Findings of EMNLP 2024)</p>
                    <p>Ziyi Liu, Soumya Sanyal, Isabelle Lee, Yongkang Du, Rahul Gupta, Yang Liu, Jieyu Zhao</p>
                    
                    <h3>2023</h3>
                    <p style="font-weight:bold;font-size:20px;">Are Machine Rationales (Not) Useful to Humans? Measuring and Improving Human Utility of Free-Text Rationales (ACL 2023)</p>
                    <p>Brihi Joshi*, Ziyi Liu*, Sahana Ramnath, Aaron Chan, Zhewei Tong, Shaoliang Nie, Qifan Wang, Yejin Choi, Xiang Ren (* means same contribution)</p>
                    
                    <h3>2022</h3>
                    <p style="font-weight:bold;font-size:20px;">ER-Test: Evaluating Explanation Regularization Methods for NLP Models (Findings of EMNLP 2022)</p>
                    <p>Brihi Joshi*, Aaron Z. Chan*, Ziyi Liu*, Shaoliang Nie, Maziar Sanjabi, Hamed Firooz and Xiang Ren(* means same contribution)</p>
                    <h3>2021</h3>
                    <p style="font-weight:bold;font-size:20px">A deep-learning framework for multi-level peptideâ€“protein interaction prediction (Nature communications)</p>
                    <p>Yipin Lei, Shuya Li, Ziyi Liu, Fangping Wan, Tingzhong Tian, Shao Li, Dan Zhao, Jianyang Zeng</p>


                </div>
              </div>
          </div>
        
    </body>
</html>